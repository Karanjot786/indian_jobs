# name: Run Scraping Script

# on:
#   schedule:
#     - cron: '0 0 * * *'
#   workflow_dispatch:

# jobs:
#   scrape:
#     runs-on: ubuntu-latest

#     steps:
#       - name: Checkout repository
#         uses: actions/checkout@v2

#       - name: Set up Python
#         uses: actions/setup-python@v2
#         with:
#           python-version: '3.10'

#       - name: Cache Python packages
#         uses: actions/cache@v3
#         with:
#           path: ~/.cache/pip
#           key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
#           restore-keys: |
#             ${{ runner.os }}-pip-

#       - name: Install dependencies
#         run: |
#           python -m pip install --upgrade pip
#           pip install -r requirements.txt

#       - name: Run scraping script
#         env:
#           PG_HOST: ${{ secrets.PG_HOST }}
#           PG_DBNAME: ${{ secrets.PG_DBNAME }}
#           PG_USER: ${{ secrets.PG_USER }}
#           PG_PASSWORD: ${{ secrets.PG_PASSWORD }}
#           PG_PORT: ${{ secrets.PG_PORT }}
#           PYTHONHTTPSVERIFY: 0
#         run: |
#           python main.py
